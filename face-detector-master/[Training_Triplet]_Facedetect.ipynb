{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Training_Triplet] Facedetect.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1599122203685",
      "display_name": "Python 3.6.6 64-bit"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "DiR7oJn4h4WE",
        "colab_type": "code",
        "outputId": "41b70c9d-f258-4f33-c91f-9043b8a90850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/4/3wGRZQUC82QsqppWK5krvUbbauWbPElGA1Ve44g4iRv7qlfEvDpoZjQ')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-eff19154862e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the Drive helper and mount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# This will prompt for authorization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive/4/3wGRZQUC82QsqppWK5krvUbbauWbPElGA1Ve44g4iRv7qlfEvDpoZjQ'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "xjYxgZ8pioMe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-dc3f73838a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ruYJq980nUVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('drive/My Drive/Machine_Learning-prj/face_detection/X_train_triplet.pkl', 'rb') as f:\n",
        "    X = pickle.load(f)\n",
        "    X = np.array(X)\n",
        "#     X = np.expand_dims(X, axis=3)\n",
        "    X = X/255.\n",
        "with open('drive/My Drive/Machine_Learning-prj/face_detection/y_train_triplet.pkl', 'rb') as f:\n",
        "    y = pickle.load(f)\n",
        "    y = np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uC0BtbaF9OvU",
        "colab_type": "code",
        "outputId": "25e3a038-0caf-4ff4-bf7c-0d42aa50f0ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "np.shape(X), np.shape(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8405, 221, 221, 3), (8405,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "ePUMUd7MDMxG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import sklearn.preprocessing\n",
        "\n",
        "# label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
        "\n",
        "# label_binarizer.fit(range(4))\n",
        "\n",
        "# y = label_binarizer.transform(y)\n",
        "# y_val = label_binarizer.transform(y_val)\n",
        "\n",
        "# print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iPYMxN2tvgF5",
        "colab_type": "code",
        "outputId": "5ff64e7c-ea09-410b-b2b9-f56d1b71b4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import applications"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d84U9ihiHbFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import h5py\n",
        "\n",
        "\n",
        "def convnet_model_():\n",
        "    vgg_model = applications.VGG16(weights=None, include_top=False, input_shape=(221, 221, 3))\n",
        "    x = vgg_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.6)(x)\n",
        "    x = Lambda(lambda x_: K.l2_normalize(x,axis=1))(x)\n",
        "#     x = Lambda(K.l2_normalize)(x)\n",
        "    convnet_model = Model(inputs=vgg_model.input, outputs=x)\n",
        "    return convnet_model\n",
        "\n",
        "def deep_rank_model():\n",
        "    convnet_model = convnet_model_()\n",
        "\n",
        "    first_input = Input(shape=(221, 221, 3))\n",
        "    first_conv = Conv2D(96, kernel_size=(8,8), strides=(16,16), padding='same')(first_input)\n",
        "    first_max = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')(first_conv)\n",
        "    first_max = Flatten()(first_max)\n",
        "#     first_max = Lambda(K.l2_normalize)(first_max)\n",
        "    first_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(first_max)\n",
        "\n",
        "    second_input = Input(shape=(221, 221, 3))\n",
        "    second_conv = Conv2D(96, kernel_size=(8,8), strides=(32,32), padding='same')(second_input)\n",
        "    second_max = MaxPool2D(pool_size=(7,7), strides=(4,4), padding='same')(second_conv)\n",
        "    second_max = Flatten()(second_max)\n",
        "    second_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(second_max)\n",
        "#     second_max = Lambda(K.l2_normalize)(second_max)\n",
        "                       \n",
        "    merge_one = concatenate([first_max, second_max])\n",
        "    merge_two = concatenate([merge_one, convnet_model.output])\n",
        "    emb = Dense(4096)(merge_two)\n",
        "    emb = Dense(128)(emb)\n",
        "    l2_norm_final = Lambda(lambda x: K.l2_normalize(x, axis=1))(emb)\n",
        "#     l2_norm_final = Lambda(K.l2_normalize)(emb)\n",
        "                        \n",
        "    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n",
        "\n",
        "    return final_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rVwwf38VHmWq",
        "colab_type": "code",
        "outputId": "e9afc2cc-07c8-4b6b-bce2-fe66a5200bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1708
        }
      },
      "cell_type": "code",
      "source": [
        "deep_rank_model = deep_rank_model()\n",
        "deep_rank_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 221, 221, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 221, 221, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 110, 110, 64) 0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 110, 110, 128 73856       block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 110, 110, 128 147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 55, 55, 256)  295168      block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 55, 55, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 55, 55, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 27, 27, 256)  0           block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 27, 27, 512)  1180160     block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 27, 27, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 27, 27, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 13, 13, 512)  0           block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 13, 13, 512)  2359808     block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 13, 13, 512)  2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 13, 13, 512)  2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 6, 6, 512)    0           block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            (None, 221, 221, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 512)          0           block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 14, 14, 96)   18528       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 7, 7, 96)     18528       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 4096)         2101248     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 96)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 2, 2, 96)     0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4704)         0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 384)          0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 4096)         16781312    dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 4704)         0           flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 384)          0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 4096)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5088)         0           lambda_2[0][0]                   \n",
            "                                                                 lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 4096)         0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 9184)         0           concatenate_1[0][0]              \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 4096)         37621760    concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 128)          524416      dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 128)          0           dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 71,780,480\n",
            "Trainable params: 71,780,480\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHY7XziPKu94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 24\n",
        "\n",
        "_EPSILON = K.epsilon()\n",
        "def _loss_tensor(y_true, y_pred):\n",
        "    y_pred = K.clip(y_pred, _EPSILON, 1.0 - _EPSILON)\n",
        "    loss = 0.\n",
        "    g = 1.\n",
        "    for i in range(0, batch_size, 3):\n",
        "        try:\n",
        "            q_embedding = y_pred[i]\n",
        "            p_embedding = y_pred[i+1]\n",
        "            n_embedding = y_pred[i+2]\n",
        "            D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2))\n",
        "            D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2))\n",
        "            loss = loss + g + D_q_p - D_q_n\n",
        "        except:\n",
        "            continue\n",
        "    loss = loss/batch_size*3\n",
        "    return K.maximum(loss, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h2lcWgrgK2HH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "deep_rank_model.compile(loss=_loss_tensor, optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4AZD-UMIbjA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def image_batch_generator(images, labels, batch_size):\n",
        "    labels = np.array(labels)\n",
        "    while True:\n",
        "        batch_paths = np.random.choice(a = len(images), size = batch_size//3)\n",
        "        input_1 = []\n",
        "        \n",
        "        for i in batch_paths:\n",
        "            pos = np.where(labels == labels[i])[0]\n",
        "            neg = np.where(labels != labels[i])[0]\n",
        "            \n",
        "            j = np.random.choice(pos)\n",
        "            while j == i:\n",
        "                j = np.random.choice(pos)\n",
        "             \n",
        "            k = np.random.choice(neg)\n",
        "            while k == i:\n",
        "                k = np.random.choice(neg)\n",
        "            \n",
        "            input_1.append(images[i])\n",
        "            input_1.append(images[j])\n",
        "            input_1.append(images[k])\n",
        "\n",
        "        input_1 = np.array(input_1)\n",
        "        input = [input_1, input_1, input_1]\n",
        "        yield(input, np.zeros((batch_size, )))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEQ3O2pqMFf9",
        "colab_type": "code",
        "outputId": "16a93174-2e2f-4548-9b57-32d4663adc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "print(\"Loading pre-trained weight\")\n",
        "deep_rank_model.load_weights('drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pre-trained weight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uNpgPSzSz_4g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = 'drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-QTwIM190EKg",
        "colab_type": "code",
        "outputId": "937caf4a-0e55-46cc-9303-1960f9f88350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2820
        }
      },
      "cell_type": "code",
      "source": [
        "deep_rank_model.fit_generator(generator=image_batch_generator(X, y, batch_size),\n",
        "                   steps_per_epoch=len(X)//batch_size,\n",
        "                   epochs=2000,\n",
        "                   verbose=1,\n",
        "                   callbacks=callbacks_list)\n",
        "     "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "350/350 [==============================] - 283s 810ms/step - loss: 0.4185\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.41851, saving model to drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5\n",
            "Epoch 2/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4180\n",
            "\n",
            "Epoch 00002: loss improved from 0.41851 to 0.41805, saving model to drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5\n",
            "Epoch 3/2000\n",
            "350/350 [==============================] - 272s 779ms/step - loss: 0.4041\n",
            "\n",
            "Epoch 00003: loss improved from 0.41805 to 0.40406, saving model to drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5\n",
            "Epoch 4/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4037\n",
            "\n",
            "Epoch 00004: loss improved from 0.40406 to 0.40370, saving model to drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5\n",
            "Epoch 5/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4259\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.40370\n",
            "Epoch 6/2000\n",
            "350/350 [==============================] - 272s 777ms/step - loss: 0.4130\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.40370\n",
            "Epoch 7/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4239\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.40370\n",
            "Epoch 8/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4121\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.40370\n",
            "Epoch 9/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4184\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.40370\n",
            "Epoch 10/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4142\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.40370\n",
            "Epoch 11/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4138\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.40370\n",
            "Epoch 12/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4106\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.40370\n",
            "Epoch 13/2000\n",
            "350/350 [==============================] - 272s 778ms/step - loss: 0.4090\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.40370\n",
            "Epoch 14/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4180\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.40370\n",
            "Epoch 15/2000\n",
            "350/350 [==============================] - 273s 780ms/step - loss: 0.4077\n",
            "\n",
            "Epoch 00015: loss did not improve from 0.40370\n",
            "Epoch 16/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4162\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.40370\n",
            "Epoch 17/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4050\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.40370\n",
            "Epoch 18/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4067\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.40370\n",
            "Epoch 19/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4160\n",
            "\n",
            "Epoch 00019: loss did not improve from 0.40370\n",
            "Epoch 20/2000\n",
            "350/350 [==============================] - 273s 779ms/step - loss: 0.4006\n",
            "\n",
            "Epoch 00020: loss improved from 0.40370 to 0.40062, saving model to drive/My Drive/Machine_Learning-prj/face_detection/triplet_weight.hdf5\n",
            "Epoch 21/2000\n",
            "350/350 [==============================] - 273s 780ms/step - loss: 0.4109\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.40062\n",
            "Epoch 22/2000\n",
            "145/350 [===========>..................] - ETA: 2:39 - loss: 0.4219"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9daaf7c6a5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                    callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "11PIHM8Tx2mD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}